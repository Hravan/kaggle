{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext import data\n",
    "\n",
    "from quoraquestionpairs.data import get_dataset\n",
    "from quoraquestionpairs.neuralnets import RNNGRUSequential\n",
    "from quoraquestionpairs.training import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = data.Field(tokenize='spacy',\n",
    "                      lower=True,\n",
    "                      pad_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = get_dataset('data/train.csv', question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = data_df.split(0.95, stratified=True, strata_field='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question.build_vocab(train_ds,\n",
    "                     min_freq=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural net structure\n",
    "Input: two sequences\n",
    "[?1 x 1], [?2 x 1]\n",
    "\n",
    "Embedding layer:\n",
    "-> [n_vocab, embedding_dim] -> [?1 x embedding_dim], [?2 x embedding_dim]\n",
    "\n",
    "Concatenation:\n",
    "-> [?1 + ?2 x embedding_dim]\n",
    "\n",
    "GRU:\n",
    "-> [embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1 = torch.tensor([1, 2, 0])\n",
    "# x2 = torch.tensor([2, 0])\n",
    "\n",
    "# emb = nn.Embedding(3, 10)\n",
    "\n",
    "# x1_emb = emb(x1)\n",
    "# x2_emb = emb(x2)\n",
    "\n",
    "# assert x1_emb.size() == torch.Size([3, 10]) and x2_emb.size() == torch.Size([2, 10])\n",
    "\n",
    "# concatenated = torch.cat([x1_emb, x2_emb])\n",
    "\n",
    "# assert concatenated.size() == torch.Size([5, 10])\n",
    "\n",
    "# gru = nn.GRU(input_size=10, hidden_size=8)\n",
    "# _, x = gru(concatenated.view(-1, 1, 10))\n",
    "\n",
    "# assert x.size() == torch.Size([1, 1, 8])\n",
    "\n",
    "# linear = nn.Linear(8, 1)\n",
    "\n",
    "# out = torch.sigmoid(linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNNGRUSequential(len(question.vocab), 300, 128).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = data.Iterator(train_ds,\n",
    "                           batch_size=256,\n",
    "                           repeat=False,\n",
    "                           shuffle=True,\n",
    "                           device=device)\n",
    "    \n",
    "val_iter = data.Iterator(val_ds,\n",
    "                         batch_size=256,\n",
    "                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples processed: 100096 Loss: 0.002081677955670563\n",
      "Samples processed: 100096 Loss: 0.0019575727098952514\n",
      "Samples processed: 100096 Loss: 0.0019197972640847725\n",
      "Epoch: 1 Val accuracy: 76.10759493670885\n",
      "Samples processed: 100096 Loss: 0.0018354402074966666\n",
      "Samples processed: 100096 Loss: 0.0018658884652101857\n",
      "Samples processed: 100096 Loss: 0.0018575213583962768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8c018c859c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/My_Folder/Computer_science/Data_science/kaggle/Quora_Question_Pairs/quoraquestionpairs/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, n_iter, train_iter, val_iter, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mn_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#* target.size(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(rnn, criterion, optimizer, 10, train_iter, val_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, ((x1, x2), target) in enumerate(train_iter):\n",
    "        x1 = x1.to(device)\n",
    "        x2 = x2.to(device)\n",
    "        target = target.type(torch.FloatTensor).to(device) #target.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = rnn(x1, x2)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 250 == 0:\n",
    "            print('Batch: {} Loss: {}'.format(i + 1, running_loss / 250))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (x1, x2), target in val_iter:\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "            target = target.type(torch.ByteTensor).to(device)\n",
    "            output = rnn(x1, x2)\n",
    "            output = output\n",
    "            pred = output >= 0.5\n",
    "            correct += (target == pred).sum().item()\n",
    "            total += 256\n",
    "        \n",
    "    print('Epoch: {} Val accuracy: {}'.format(epoch + 1, correct / total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuoraDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file, train=False, transform=None):\n",
    "        self.questions = pd.read_csv(csv_file, keep_default_na=False)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = {'q1': self.questions.loc[idx, 'question1'],\n",
    "                  'q2': self.questions.loc[idx, 'question2']}\n",
    "        \n",
    "        if self.train:\n",
    "            sample['target'] = self.questions.loc[idx, 'is_duplicate']\n",
    "            \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def get_tokens(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QuoraDataset('train.csv', train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = defaultdict(int)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i]\n",
    "    questions = [tokenizer(sample['q1']), tokenizer(sample['q2'])]\n",
    "    for token in chain(*questions):\n",
    "        word = token.text.lower()\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        else:\n",
    "            word_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_words = sorted([(word, counts) for word, counts in word_dict.items()], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordTokenizer:\n",
    "    \n",
    "    def __init__(self, num_words):\n",
    "        self.num_words = num_words\n",
    "    \n",
    "    def tokenize(self, *args):\n",
    "        words_counts = defaultdict(int)\n",
    "        \n",
    "        for text in chain(*args):\n",
    "            for token in tokenizer(text):\n",
    "                word = token.text.lower()\n",
    "                if token.is_stop:\n",
    "                    continue\n",
    "                else:\n",
    "                    words_counts[word] += 1\n",
    "        \n",
    "        words_counts = sorted([(word, counts) for word, counts in words_counts.items()], key=lambda x: x[1], reverse=True)\n",
    "        self.words_dict = {word: i for i, (word, counts) in enumerate(sorted_words, 1)}\n",
    "    \n",
    "    def __call__(self, seq):\n",
    "        int_seq = [self.words_dict[word] for word in ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{word: i for i, (word, counts) in enumerate(sorted_words, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fun(*args):\n",
    "    for i in chain(*args):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset.questions['question1'].values:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = WordTokenizer(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_fun(dataset.questions['question1'].values, dataset.questions['question2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer.tokenize(dataset.questions['question1'].values, dataset.questions['question2'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
